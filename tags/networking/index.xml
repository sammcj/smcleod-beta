<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>networking on smcleod.net</title><link>https://smcleod.net/tags/networking/</link><description>Recent content in networking on smcleod.net</description><generator>Hugo -- gohugo.io</generator><language>en-au</language><copyright>Sam McLeod</copyright><lastBuildDate>Fri, 13 Oct 2017 00:00:00 +0000</lastBuildDate><atom:link href="https://smcleod.net/tags/networking/index.xml" rel="self" type="application/rss+xml"/><item><title>Broadcom, Or How I Learned To Start Worrying And Drop The Packet</title><link>https://smcleod.net/2017/10/broadcom-or-how-i-learned-to-start-worrying-and-drop-the-packet/</link><pubDate>Fri, 13 Oct 2017 00:00:00 +0000</pubDate><guid>https://smcleod.net/2017/10/broadcom-or-how-i-learned-to-start-worrying-and-drop-the-packet/</guid><description>&lt;p>Earlier this week we started the process to upgrade one of our hypervisor compute clusters when we encountered a rather painful bug with HP&amp;rsquo;s Broadcom NIC chipsets.&lt;/p>
&lt;p>We were part way through a routine rolling pool upgrade of our hypervisor (XenServer) cluster when we observed unexpected and intermittent loss of connectivity between several VMs, then entire XenServer hosts.&lt;/p>
&lt;p>The problems appeared to impact hosts that hadn&amp;rsquo;t yet upgraded to XenServer 7.2. We now attribute this to a symptom of extreme packet loss between the hosts in the pool and thanks to buggy firmware from Broadcom and HP.&lt;/p></description></item><item><title>Speeding Up rsync</title><link>https://smcleod.net/2016/05/speeding-up-rsync/</link><pubDate>Tue, 03 May 2016 00:00:00 +0000</pubDate><guid>https://smcleod.net/2016/05/speeding-up-rsync/</guid><description>&lt;p>The most common way to use rsync is probably as such:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>rsync -avr user@&amp;lt;source&amp;gt;:&amp;lt;source_dir&amp;gt; &amp;lt;dest_dir&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Resulting in 30-35MB/s depending on file sizes&lt;/p>
&lt;p>This can be improved by using a more efficient, less secure encryption algorithm, disabling compression
and telling the SSH client to disable some unneeded features that slow things down.&lt;/p>
&lt;p>With the settings below I have achieved 100MB/s (at work between VMs) and over 300MB/s at home between SSD drives.&lt;/p></description></item><item><title>Replacing Junos Pulse with OpenConnect</title><link>https://smcleod.net/2015/09/replacing-junos-pulse-with-openconnect/</link><pubDate>Tue, 22 Sep 2015 00:00:00 +0000</pubDate><guid>https://smcleod.net/2015/09/replacing-junos-pulse-with-openconnect/</guid><description>&lt;p>In an attempt to avoid using the Juniper Pulse (Now Pulse Secure) VPN client we tried OpenConnect but found that DNS did not work correctly when connected to the VPN.
This bug has now been resolved recently but has not made it&amp;rsquo;s way into a new build, in fact there have been no releases for 6 months.&lt;/p>
&lt;p>Luckily the OpenConnect was not too difficult to build from source.&lt;/p></description></item></channel></rss>